<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>负载均衡和一致性哈希 | ChrisChen - 尾張</title>
<meta name=keywords content><meta name=description content="负载均衡和一致性哈希
反向代理 reverse proxy 是指以代理服务器来接收由客户端发送来的请求，并通过一定的策略将其转变发给实际处理请求的后端服务器；主要应用于负载均衡、动态缓存、安全认证、内网穿透、SSL 加密等；而负载均衡 load balancing 是指在多个 slot（槽，一般是某种计算资源）中分配负载，以优化资源利用率和避免单点故障问题的方法，是高可用性分布式系统的必备中间件；常用的开源 load balancer 有 nginx，LVS，Haproxy 等；负载均衡可以视为反向代理的一种应用，负载均衡的方法大致可以分为传统负载均衡算法和哈希算法两种，本文简单地总结了这些算法的原理。

1 传统负载均衡算法

随机 random：将 key 随机分配到某一个 slot 上，根据概率论可知，吞吐量越大，随机算法的效果越好；
加权随机 weighted random：为每一个 slot 分配一个权重，在随机的时候考虑权重的影响；可以通过在所有 slot 的权重总和中随机出一个数字 k，找到 k 所在的 slot 位置来实现；
轮询 round robin：按顺序依次将 key 分配给每一个 slot；
加权轮询 weighted round robin：为每一个 slot 分配一个权重，在按序分配时为权重更高的 slot 分配更多的 key；
平滑加权轮询 smooth weighted round robin：一种能够均匀地分散调度序列的加权轮询方法，分为以下几个步骤：

选出当前权重最高的 slot，将 key 分配给它；
将选出的 slot 的权重数值减去其初始权重；
将所有 slot 的权重数值都加上它们的原始权重；
重复以上步骤；


最少连接数 least connections：将 key 分配给当前具有最少连接数量的 slot；

2 Mod-N 哈希
在有些场景下，传统负载均衡算法无法满足我们的需求，例如："><meta name=author content><link rel=canonical href=https://prov1dence.top/posts/service-governance/load-balancing/><link crossorigin=anonymous href=/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as=style><link rel=icon href=https://prov1dence.top/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://prov1dence.top/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://prov1dence.top/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://prov1dence.top/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://prov1dence.top/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://prov1dence.top/posts/service-governance/load-balancing/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://prov1dence.top/posts/service-governance/load-balancing/"><meta property="og:site_name" content="ChrisChen - 尾張"><meta property="og:title" content="负载均衡和一致性哈希"><meta property="og:description" content="负载均衡和一致性哈希 反向代理 reverse proxy 是指以代理服务器来接收由客户端发送来的请求，并通过一定的策略将其转变发给实际处理请求的后端服务器；主要应用于负载均衡、动态缓存、安全认证、内网穿透、SSL 加密等；而负载均衡 load balancing 是指在多个 slot（槽，一般是某种计算资源）中分配负载，以优化资源利用率和避免单点故障问题的方法，是高可用性分布式系统的必备中间件；常用的开源 load balancer 有 nginx，LVS，Haproxy 等；负载均衡可以视为反向代理的一种应用，负载均衡的方法大致可以分为传统负载均衡算法和哈希算法两种，本文简单地总结了这些算法的原理。
1 传统负载均衡算法 随机 random：将 key 随机分配到某一个 slot 上，根据概率论可知，吞吐量越大，随机算法的效果越好； 加权随机 weighted random：为每一个 slot 分配一个权重，在随机的时候考虑权重的影响；可以通过在所有 slot 的权重总和中随机出一个数字 k，找到 k 所在的 slot 位置来实现； 轮询 round robin：按顺序依次将 key 分配给每一个 slot； 加权轮询 weighted round robin：为每一个 slot 分配一个权重，在按序分配时为权重更高的 slot 分配更多的 key； 平滑加权轮询 smooth weighted round robin：一种能够均匀地分散调度序列的加权轮询方法，分为以下几个步骤： 选出当前权重最高的 slot，将 key 分配给它； 将选出的 slot 的权重数值减去其初始权重； 将所有 slot 的权重数值都加上它们的原始权重； 重复以上步骤； 最少连接数 least connections：将 key 分配给当前具有最少连接数量的 slot； 2 Mod-N 哈希 在有些场景下，传统负载均衡算法无法满足我们的需求，例如："><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-10-25T23:06:52+08:00"><meta property="article:modified_time" content="2020-10-25T23:06:52+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="负载均衡和一致性哈希"><meta name=twitter:description content="负载均衡和一致性哈希
反向代理 reverse proxy 是指以代理服务器来接收由客户端发送来的请求，并通过一定的策略将其转变发给实际处理请求的后端服务器；主要应用于负载均衡、动态缓存、安全认证、内网穿透、SSL 加密等；而负载均衡 load balancing 是指在多个 slot（槽，一般是某种计算资源）中分配负载，以优化资源利用率和避免单点故障问题的方法，是高可用性分布式系统的必备中间件；常用的开源 load balancer 有 nginx，LVS，Haproxy 等；负载均衡可以视为反向代理的一种应用，负载均衡的方法大致可以分为传统负载均衡算法和哈希算法两种，本文简单地总结了这些算法的原理。

1 传统负载均衡算法

随机 random：将 key 随机分配到某一个 slot 上，根据概率论可知，吞吐量越大，随机算法的效果越好；
加权随机 weighted random：为每一个 slot 分配一个权重，在随机的时候考虑权重的影响；可以通过在所有 slot 的权重总和中随机出一个数字 k，找到 k 所在的 slot 位置来实现；
轮询 round robin：按顺序依次将 key 分配给每一个 slot；
加权轮询 weighted round robin：为每一个 slot 分配一个权重，在按序分配时为权重更高的 slot 分配更多的 key；
平滑加权轮询 smooth weighted round robin：一种能够均匀地分散调度序列的加权轮询方法，分为以下几个步骤：

选出当前权重最高的 slot，将 key 分配给它；
将选出的 slot 的权重数值减去其初始权重；
将所有 slot 的权重数值都加上它们的原始权重；
重复以上步骤；


最少连接数 least connections：将 key 分配给当前具有最少连接数量的 slot；

2 Mod-N 哈希
在有些场景下，传统负载均衡算法无法满足我们的需求，例如："><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://prov1dence.top/posts/"},{"@type":"ListItem","position":2,"name":"负载均衡和一致性哈希","item":"https://prov1dence.top/posts/service-governance/load-balancing/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"负载均衡和一致性哈希","name":"负载均衡和一致性哈希","description":"负载均衡和一致性哈希 反向代理 reverse proxy 是指以代理服务器来接收由客户端发送来的请求，并通过一定的策略将其转变发给实际处理请求的后端服务器；主要应用于负载均衡、动态缓存、安全认证、内网穿透、SSL 加密等；而负载均衡 load balancing 是指在多个 slot（槽，一般是某种计算资源）中分配负载，以优化资源利用率和避免单点故障问题的方法，是高可用性分布式系统的必备中间件；常用的开源 load balancer 有 nginx，LVS，Haproxy 等；负载均衡可以视为反向代理的一种应用，负载均衡的方法大致可以分为传统负载均衡算法和哈希算法两种，本文简单地总结了这些算法的原理。\n1 传统负载均衡算法 随机 random：将 key 随机分配到某一个 slot 上，根据概率论可知，吞吐量越大，随机算法的效果越好； 加权随机 weighted random：为每一个 slot 分配一个权重，在随机的时候考虑权重的影响；可以通过在所有 slot 的权重总和中随机出一个数字 k，找到 k 所在的 slot 位置来实现； 轮询 round robin：按顺序依次将 key 分配给每一个 slot； 加权轮询 weighted round robin：为每一个 slot 分配一个权重，在按序分配时为权重更高的 slot 分配更多的 key； 平滑加权轮询 smooth weighted round robin：一种能够均匀地分散调度序列的加权轮询方法，分为以下几个步骤： 选出当前权重最高的 slot，将 key 分配给它； 将选出的 slot 的权重数值减去其初始权重； 将所有 slot 的权重数值都加上它们的原始权重； 重复以上步骤； 最少连接数 least connections：将 key 分配给当前具有最少连接数量的 slot； 2 Mod-N 哈希 在有些场景下，传统负载均衡算法无法满足我们的需求，例如：\n","keywords":[],"articleBody":"负载均衡和一致性哈希 反向代理 reverse proxy 是指以代理服务器来接收由客户端发送来的请求，并通过一定的策略将其转变发给实际处理请求的后端服务器；主要应用于负载均衡、动态缓存、安全认证、内网穿透、SSL 加密等；而负载均衡 load balancing 是指在多个 slot（槽，一般是某种计算资源）中分配负载，以优化资源利用率和避免单点故障问题的方法，是高可用性分布式系统的必备中间件；常用的开源 load balancer 有 nginx，LVS，Haproxy 等；负载均衡可以视为反向代理的一种应用，负载均衡的方法大致可以分为传统负载均衡算法和哈希算法两种，本文简单地总结了这些算法的原理。\n1 传统负载均衡算法 随机 random：将 key 随机分配到某一个 slot 上，根据概率论可知，吞吐量越大，随机算法的效果越好； 加权随机 weighted random：为每一个 slot 分配一个权重，在随机的时候考虑权重的影响；可以通过在所有 slot 的权重总和中随机出一个数字 k，找到 k 所在的 slot 位置来实现； 轮询 round robin：按顺序依次将 key 分配给每一个 slot； 加权轮询 weighted round robin：为每一个 slot 分配一个权重，在按序分配时为权重更高的 slot 分配更多的 key； 平滑加权轮询 smooth weighted round robin：一种能够均匀地分散调度序列的加权轮询方法，分为以下几个步骤： 选出当前权重最高的 slot，将 key 分配给它； 将选出的 slot 的权重数值减去其初始权重； 将所有 slot 的权重数值都加上它们的原始权重； 重复以上步骤； 最少连接数 least connections：将 key 分配给当前具有最少连接数量的 slot； 2 Mod-N 哈希 在有些场景下，传统负载均衡算法无法满足我们的需求，例如：\n当我们需要充分利用到 slot 的缓存，在任何时候都希望将同一个 key 映射到固定的 slot 上，而不是让其被任意地分配到一个负载较低的 slot 上； 当我们希望把数据分配到一些具有键值存储功能（可以是 memcache, redis, mysql 等）的 slot 上进行有状态服务，而又不使用一个全局的数据库； 对于以上两个问题，我们可以先使用哈希函数（如 md5, sha1 等，需要保证哈希后的分布平均）将 key 映射为一个 uint32 的值（key 本身可能是一个字符串或其他值），再用该值对 N（slot 的数量）进行取模运算来映射出一个值， 即 value = hash(key) mod n，这种方法可以称为 Mod-N 哈希；这里做了两次哈希，第一次是对 key 做映射，第二次是进行取模运算。\n一般来说好的哈希函数应该满足一些条件：\n从哈希值不可反向推导出 key； 发生哈希冲突的概率尽可能小； 效率高； 哈希冲突/碰撞 Hash Collision 当我们把较大的值空间映射到较小的值空间时，冲突是不可避免的；如果两个 key 通过哈希方法被映射为了同一个值，那么就称为发生了 hash collision，一般来说其解决方案有：\n(1) 单链表法 separate chaining 也称作 open hashing；对于每一个通过哈希方法映射出的值，我们将其作为一个 bucket；当有 key 被映射到 bucket 上时，如果 bucket 为空，则为其新分配一个链表节点，否则遍历这个链表，在这个链表的尾部为其分配新的链表节点；\n(2) 开放寻址法 open addressing 也称作 closed hashing；主要思路是通过搜索哈希表中的其他空的 slot（探测序列 probe sequence）来进行 key 的插入，进行查找时应该采用与插入时相同的线性探测规则；获取 probe sequence 的方法一般有：\n线性探测 linear probing：查找哈希表中离冲突位置最近的空的 slot，即 value = (hash(key) + k) mod n, k = 1, 2, 3, 4...\n二次探测 quadratic probing：对哈希结果添加一个二次多项式直到找到一个空的 slot，即 value = (hash(key) + k^2) mod n, k^2 = 1, 4, 9, 16...\n双重哈希 double hashing：借助另一个哈希函数 hash’ 的结果，作为偏移量获取值，即 value = hash'(key) mod n；\n3 一致性哈希 Consistent Hashing 在数据量较大的场景下，假设我们因为某些原因需要将原本的 n 个 slot 扩容为 m 个 slot，如果仍然使用 Mod-N 哈希，将会有 n/m 份缓存不能正确命中，从而产生大量的数据库请求，可能导致缓存雪崩。\n对于传统的哈希映射，添加或者删除一个 slot，会造成哈希表的全量重新映射；而**一致性哈希**的目的是达成增量式的重新映射，即当 slot 的数量发生变化时，降低重新映射的数量，尽量最小化重新映射（minimum disruption）。\n一致性哈希算法的设计关键有 4 点：\n平衡性 balance：所有的 key 能被均匀地映射到各个 slot 上； 单调性 monotonicity：增加新的 slot 后，原有的 key 应该被映射到原有的 slot，或新的 slot 上，而不是其他旧的 slot ； 分散 spread：服务扩容或者缩容时，尽量减少数据的迁移； 负载 load：尽量降低 slot 的负载； 3.1 Ketama ketama 算法是最常用的一种一致性哈希算法，也叫做哈希环法（hash ring）， 被广泛的应用在数据库，缓存系统和服务框架上，包括但不限于 memcache, redis, dubbo, nginx 等，其步骤是：\n对于一个 [0, uint32] 的区间，将其首尾相连，形成顺时针的环； 对 slot 进行哈希，映射到 [0, uint32] 区间上，并将结果标记到环上； 对 key 进行哈希，映射到区间上，沿着环顺时针寻找并将其分配到距其最近的 slot； 举个例子，假设现在有 N0, N1, N2 三个 slot 以及 a, b, c 三个 key，其中 a 会被分配 N1 上，b 和 c 都会被分配到 N2 上；\n现在我们新增一个 N3 slot，并将其映射到 [a, N1] 之间，那么 a 和所有在 [N0, N3] 之间的 key 都会被重新分配到 N3 这个 slot 上，除此之外的其他所有 key 则不会被重新映射；\n假设我们移除 N2 slot，那么所有在 [N1, N2] 之间的 key 都会被重新映射到 N0 上，除此之外的其他所有 key 则不会被重新映射。\n可以发现，ketama 算法达成了在新增或移除 slot 后的增量式重新映射（minimum disruption），不会破坏大多数 key 的映射关系；因为要构造出一个环来存储所有 slot 的 key 被映射到的位置，所以其空间复杂度是 O(n)；为了方便地进行查找，可以将环转换成一个有序数组，在其中进行二分查找，时间复杂度是 O(logn)。\n虚拟节点 有时候我们可能会对不同的节点赋予不同的权重，也就导致了每个节点的地位不平等，从而不能直接将节点放在环上，解决方案是使用不同数量的虚拟节点（virtual node）来代表实际的节点，一般来说每个虚拟节点代表一个单位节点，虚拟节点数量之和等于实际节点的权重；即使不同节点之间的权重相同，也建议将一个实际节点映射为多个虚拟节点，因为节点越多，它们在环上的分布就越均匀，因此使用虚拟节点还可以降低节点之间的负载差异；假设 N0, N1, N2 三个节点具有相同的权重，那么用虚拟节点代替之后则大致如图：\n3.2 Jump Consistent Hashing Jump Consistent Hashing 跳跃一致性哈希是 Google 发表的一个非常简洁的一致性哈希算法，其主要思路是：\n假设有 n 个 slot 和 k 个 key，所有的 k 个 key 都被均匀地映射到了这 n 个 slot 上； 现在增加 1 个 slot，为了将原有的 k 个 key 均匀地映射到 n + 1 个 slot 上，需要将其中 k / n + 1 个 key 进行重新映射，即每次增加 1 个 slot 都需要重新映射 k / n + 1 个 key； 使用**伪随机**的方式（给定一个随机种子，生成一个固定的随机序列）来决定哪 k / n 个 key 需要被重新映射； 这里使用伪随机的含义是，对于每一个 key，我们使用这个 key 来作为随机种子，生成一个固定的随机序列 seq，于是 seq 在其下标为 [1, n] 的区间里的值都是固定的；接下来遍历 seq，在每一次迭代 i 中，如果 seq[i] \u003c 1/i，则将其重新分配到第 i 个 slot 上，否则保持不变；整个过程在给定 key 时就已经确定了。\n这样一来就达成了一致性哈希的平衡性和单调性，没有使用额外的内存，所以空间复杂度是 O(1)；而因为遍历了 n 个 slot，所以时间复杂度是 O(n)，还可以从时间复杂度的角度继续优化；在 seq[i] \u003c 1 / i 这个公式中（即被重新分配这个假设成立），1 / i 会随着 i 的增大而变得越来越小，而 seq[i] 是随机数，因此可以认为公式成立的概率会越来越小，所以我们可以让 i 的步进增大，来减少迭代的次数。\n假设当前 key 所在的 slot 是 b，迭代次数是 b + 1 ，下一次迭代某一个 key 会被重新映射的概率是 1 / b + 2（上面思路第 2 点），即其不会被重新分配到新 slot 的概率为 b + 1 / b + 2，再下一次的概率是 b + 2 / b + 3，直到第 j 次的概率是 j - 1 / j，将这些概率相乘得到在这 j - b 次之间 key 不会被重新分配的概率是 b + 1 / j；假设把 seq[i] 用 r = random.next() 来表示，要使得 r \u003c (b + 1) / j（即被重新分配这个假设成立），就必须有 j \u003c (b + 1) / r，那么 key 在步进大于等于 (b + 1) / r 次后一定会被重新分配。\n这样一来时间复杂度就减少到了 O(ln(n))；但其局限性也很明显，因为只能通过步进的方式来重新映射和分配 slot，导致其只能在尾部增删 slot，否则在中间进行增删的话会导致其后续的 slot 下标和步进关系都发生变化，\n论文中还对比了其与哈希环法的运行时间。\n3.3 Maglev Hashing Maglev 是 Google 研发的一个负载均衡组件，使用了其自研的一致性哈希算法 Maglev Hashing，其主要思路是通过维护两个 table 来将 key 映射到 slot 上；一个表是 lookup table 查找表，用于将 key 映射到 slot 上；另一个表是 permutation table 排列表，用于记录一个 slot 在 lookup table 中的位置序列：\n对于 n 个 slot 和一个长度为 m 的映射序列（即 permutation table 和 lookup table 的长度），我们希望为每一个下标为 i 的 slot 都计算出一个数量为 m 的排列，计算时需要使用两个不同的哈希函数 h1 和 h2，来计算 offset 和 skip 两个值（这里需要保证每一个 slot 的 name 都不相同）：\n举个例子，假设 n = 3，m = 7，对于下标为 0 的 slot，通过某两个哈希函数计算出来的 offset = 3，skip = 4，为其生成一个长度 m = 7 的 permutation：\npermutation[i][0] = (3 + 0 * 4) mod 7 = 3 permutation[i][1] = (3 + 1 * 4) mod 7 = 0 permutation[i][2] = (3 + 2 * 4) mod 7 = 4 permutation[i][3] = (3 + 3 * 4) mod 7 = 1 permutation[i][4] = (3 + 4 * 4) mod 7 = 5 permutation[i][5] = (3 + 5 * 4) mod 7 = 2 permutation[i][6] = (3 + 6 * 4) mod 7 = 6 再加上另外两个计算好 permutation 的下标为 1 和 2 的 slot，对应的 permutation table：\nm s0 s1 s2 0 3 0 3 1 0 2 4 2 4 4 5 3 1 6 6 4 5 1 0 5 2 3 1 6 6 5 2 现在我们让 3 个 slot 轮流地从其 permutation 中，按顺序选择第一个没有被分配的 key，来填充到之后的 lookup table 中，流程是：\ns0 的 permutation 中的第一个数字 3 没有被分配，选择 3； s1 的 permutation 中的第一个数字 0 没有被分配，选择 0； s2 的 permutation 中的第一个数字 3 已经被分配了，往后遍历到数字 4，选择 4； s0 在 permutation 中往后遍历，0 和 4 都已经被分配了，选择 1； s1 在 permutation 中往后遍历，选择 2； s2 在 permutation 中往后遍历，4 已经被分配了，选择 5； s0 在 permutation 中往后遍历直到选择 6； 于是就有了 lookup table：\nm slot 0 s1 1 s0 2 s1 3 s0 4 s2 5 s2 6 s0 这种方法类似于开放寻址法中的双重哈希，通过使用两个无关的哈希函数来生成排列（也可以使用其他生成随机排列的方法，例如 fisher-yates shuffle，必须保证方法的的随机性）降低了哈希碰撞的概率；在增加或移除 slot 时，需要为新的 slot 生成 permutation table，再重新生成 lookup table，这会导致部分重新映射，不满足最小化重新映射（minimum disruption）；维护两个表的空间复杂度是 O(n)，查询的时间复杂度是 O(1)；建立表的复杂度可以参考论文的第 3.4 节。\n4 总结 本文主要介绍了负载均衡的概念，并简单地阐明了一致性哈希算法的原理，关于一致性哈希算法的优缺点、边界条件、复杂度分析、效率对比、实际应用等还需要结合论文和开源组件进行更深入的了解。\n","wordCount":"833","inLanguage":"en","datePublished":"2020-10-25T23:06:52+08:00","dateModified":"2020-10-25T23:06:52+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://prov1dence.top/posts/service-governance/load-balancing/"},"publisher":{"@type":"Organization","name":"ChrisChen - 尾張","logo":{"@type":"ImageObject","url":"https://prov1dence.top/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://prov1dence.top/ accesskey=h title="尾張 (Alt + H)">尾張</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://prov1dence.top/archives/ title=Posts><span>Posts</span></a></li><li><a href=https://prov1dence.top/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://prov1dence.top/>Home</a>&nbsp;»&nbsp;<a href=https://prov1dence.top/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">负载均衡和一致性哈希</h1><div class=post-meta><span title='2020-10-25 23:06:52 +0800 +0800'>October 25, 2020</span>&nbsp;·&nbsp;4 min</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e8%b4%9f%e8%bd%bd%e5%9d%87%e8%a1%a1%e5%92%8c%e4%b8%80%e8%87%b4%e6%80%a7%e5%93%88%e5%b8%8c aria-label=负载均衡和一致性哈希>负载均衡和一致性哈希</a><ul><li><a href=#1-%e4%bc%a0%e7%bb%9f%e8%b4%9f%e8%bd%bd%e5%9d%87%e8%a1%a1%e7%ae%97%e6%b3%95 aria-label="1 传统负载均衡算法">1 传统负载均衡算法</a></li><li><a href=#2-mod-n-%e5%93%88%e5%b8%8c aria-label="2 Mod-N 哈希">2 Mod-N 哈希</a><ul><li><a href=#%e5%93%88%e5%b8%8c%e5%86%b2%e7%aa%81%e7%a2%b0%e6%92%9e-hash-collision aria-label="哈希冲突/碰撞 Hash Collision">哈希冲突/碰撞 Hash Collision</a><ul><li><a href=#1-%e5%8d%95%e9%93%be%e8%a1%a8%e6%b3%95-separate-chaining aria-label="(1) 单链表法 separate chaining">(1) 单链表法 separate chaining</a></li><li><a href=#2-%e5%bc%80%e6%94%be%e5%af%bb%e5%9d%80%e6%b3%95-open-addressing aria-label="(2) 开放寻址法 open addressing">(2) 开放寻址法 open addressing</a></li></ul></li></ul></li><li><a href=#3-%e4%b8%80%e8%87%b4%e6%80%a7%e5%93%88%e5%b8%8c-consistent-hashing aria-label="3 一致性哈希 Consistent Hashing">3 一致性哈希 Consistent Hashing</a><ul><li><a href=#31-ketama aria-label="3.1 Ketama">3.1 Ketama</a><ul><li><a href=#%e8%99%9a%e6%8b%9f%e8%8a%82%e7%82%b9 aria-label=虚拟节点>虚拟节点</a></li></ul></li><li><a href=#32-jump-consistent-hashing aria-label="3.2 Jump Consistent Hashing">3.2 Jump Consistent Hashing</a></li><li><a href=#33-maglev-hashing aria-label="3.3 Maglev Hashing">3.3 Maglev Hashing</a></li></ul></li><li><a href=#4-%e6%80%bb%e7%bb%93 aria-label="4 总结">4 总结</a></li></ul></li></ul></div></details></div><div class=post-content><h1 id=负载均衡和一致性哈希>负载均衡和一致性哈希<a hidden class=anchor aria-hidden=true href=#负载均衡和一致性哈希>#</a></h1><p>反向代理 reverse proxy 是指以代理服务器来接收由客户端发送来的请求，并通过一定的策略将其转变发给实际处理请求的后端服务器；主要应用于负载均衡、动态缓存、安全认证、内网穿透、SSL 加密等；而负载均衡 load balancing 是指在多个 slot（槽，一般是某种计算资源）中分配负载，以优化资源利用率和避免单点故障问题的方法，是高可用性分布式系统的必备中间件；常用的开源 load balancer 有 nginx，LVS，Haproxy 等；负载均衡可以视为反向代理的一种应用，负载均衡的方法大致可以分为传统负载均衡算法和哈希算法两种，本文简单地总结了这些算法的原理。</p><p><img alt=reveser-proxy loading=lazy src=https://raw.githubusercontent.com/chr1sc2y/warehouse-deprecated/refs/heads/main/resources/reverse-proxy/reverse-proxy.png></p><h2 id=1-传统负载均衡算法>1 传统负载均衡算法<a hidden class=anchor aria-hidden=true href=#1-传统负载均衡算法>#</a></h2><ol><li>随机 random：将 key 随机分配到某一个 slot 上，根据概率论可知，吞吐量越大，随机算法的效果越好；</li><li>加权随机 weighted random：为每一个 slot 分配一个权重，在随机的时候考虑权重的影响；可以通过在所有 slot 的权重总和中随机出一个数字 k，找到 k 所在的 slot 位置来实现；</li><li>轮询 round robin：按顺序依次将 key 分配给每一个 slot；</li><li>加权轮询 weighted round robin：为每一个 slot 分配一个权重，在按序分配时为权重更高的 slot 分配更多的 key；</li><li>平滑加权轮询 smooth weighted round robin：一种能够均匀地分散调度序列的加权轮询方法，分为以下几个步骤：<ol><li>选出当前权重最高的 slot，将 key 分配给它；</li><li>将选出的 slot 的权重数值减去其初始权重；</li><li>将所有 slot 的权重数值都加上它们的原始权重；</li><li>重复以上步骤；</li></ol></li><li>最少连接数 least connections：将 key 分配给当前具有最少连接数量的 slot；</li></ol><h2 id=2-mod-n-哈希>2 Mod-N 哈希<a hidden class=anchor aria-hidden=true href=#2-mod-n-哈希>#</a></h2><p>在有些场景下，传统负载均衡算法无法满足我们的需求，例如：</p><ol><li>当我们需要充分利用到 slot 的缓存，在任何时候都希望将同一个 key 映射到固定的 slot 上，而不是让其被任意地分配到一个负载较低的 slot 上；</li><li>当我们希望把数据分配到一些具有键值存储功能（可以是 memcache, redis, mysql 等）的 slot 上进行有状态服务，而又不使用一个全局的数据库；</li></ol><p>对于以上两个问题，我们可以先使用哈希函数（如 md5, sha1 等，需要保证哈希后的分布平均）将 key 映射为一个 <code>uint32</code> 的值（key 本身可能是一个字符串或其他值），再用该值对 N（slot 的数量）进行取模运算来映射出一个值， 即 <code>value = hash(key) mod n</code>，这种方法可以称为 Mod-N 哈希；这里做了两次哈希，第一次是对 key 做映射，第二次是进行取模运算。</p><p>一般来说好的哈希函数应该满足一些条件：</p><ol><li>从哈希值不可反向推导出 key；</li><li>发生哈希冲突的概率尽可能小；</li><li>效率高；</li></ol><h3 id=哈希冲突碰撞-hash-collision>哈希冲突/碰撞 Hash Collision<a hidden class=anchor aria-hidden=true href=#哈希冲突碰撞-hash-collision>#</a></h3><p>当我们把较大的值空间映射到较小的值空间时，冲突是不可避免的；如果两个 key 通过哈希方法被映射为了同一个值，那么就称为发生了 <a href=https://en.wikipedia.org/wiki/Hash_table#Collision_resolution>hash collision</a>，一般来说其解决方案有：</p><h4 id=1-单链表法-separate-chaining>(1) 单链表法 separate chaining<a hidden class=anchor aria-hidden=true href=#1-单链表法-separate-chaining>#</a></h4><p>也称作 open hashing；对于每一个通过哈希方法映射出的值，我们将其作为一个 bucket；当有 key 被映射到 bucket 上时，如果 bucket 为空，则为其新分配一个链表节点，否则遍历这个链表，在这个链表的尾部为其分配新的链表节点；</p><p><img alt=separate-chaining loading=lazy src=https://raw.githubusercontent.com/chr1sc2y/warehouse-deprecated/refs/heads/main/resources/consistent-hashing/separate-chaining.png></p><h4 id=2-开放寻址法-open-addressing>(2) 开放寻址法 open addressing<a hidden class=anchor aria-hidden=true href=#2-开放寻址法-open-addressing>#</a></h4><p>也称作 closed hashing；主要思路是通过搜索哈希表中的其他空的 slot（探测序列 probe sequence）来进行 key 的插入，进行查找时应该采用与插入时相同的线性探测规则；获取 probe sequence 的方法一般有：</p><ol><li><p>线性探测 linear probing：查找哈希表中离冲突位置最近的空的 slot，即 <code>value = (hash(key) + k) mod n, k = 1, 2, 3, 4...</code></p><p><img alt=open-addressing loading=lazy src=https://raw.githubusercontent.com/chr1sc2y/warehouse-deprecated/refs/heads/main/resources/consistent-hashing/open-addressing.png></p></li><li><p>二次探测 quadratic probing：对哈希结果添加一个二次多项式直到找到一个空的 slot，即 <code>value = (hash(key) + k^2) mod n, k^2 = 1, 4, 9, 16...</code></p></li><li><p>双重哈希 double hashing：借助另一个哈希函数 hash&rsquo; 的结果，作为偏移量获取值，即 <code>value = hash'(key) mod n</code>；</p></li></ol><h2 id=3-一致性哈希-consistent-hashing>3 一致性哈希 Consistent Hashing<a hidden class=anchor aria-hidden=true href=#3-一致性哈希-consistent-hashing>#</a></h2><p>在数据量较大的场景下，假设我们因为某些原因需要将原本的 n 个 slot 扩容为 m 个 slot，如果仍然使用 Mod-N 哈希，将会有 n/m 份缓存不能正确命中，从而产生大量的数据库请求，可能导致<a href=https://alibaba-cloud.medium.com/struggling-with-poor-responsiveness-unlock-the-power-of-caching-b3186f2b3cd0>缓存雪崩</a>。</p><p>对于传统的哈希映射，添加或者删除一个 slot，会造成哈希表的全量重新映射；而**<a href=https://dl.acm.org/doi/10.1145/258533.258660>一致性哈希</a>**的目的是达成增量式的重新映射，即当 slot 的数量发生变化时，降低重新映射的数量，尽量最小化重新映射（minimum disruption）。</p><p>一致性哈希算法的设计关键有 4 点：</p><ol><li>平衡性 balance：所有的 key 能被均匀地映射到各个 slot 上；</li><li>单调性 monotonicity：增加新的 slot 后，原有的 key 应该被映射到原有的 slot，或新的 slot 上，而不是其他旧的 slot ；</li><li>分散 spread：服务扩容或者缩容时，尽量减少数据的迁移；</li><li>负载 load：尽量降低 slot 的负载；</li></ol><h3 id=31-ketama>3.1 Ketama<a hidden class=anchor aria-hidden=true href=#31-ketama>#</a></h3><p><a href="https://www.metabrew.com/article/libketama-consistent-hashing-algo-memcached-clients#:~:text=Ketama%20is%20an%20implementation%20of,complete%20remap%20of%20all%20keys.">ketama</a> 算法是最常用的一种一致性哈希算法，也叫做哈希环法（hash ring）， 被广泛的应用在数据库，缓存系统和服务框架上，包括但不限于 memcache, redis, dubbo, nginx 等，其步骤是：</p><ol><li>对于一个 [0, uint32] 的区间，将其首尾相连，形成顺时针的环；</li><li>对 slot 进行哈希，映射到 [0, uint32] 区间上，并将结果标记到环上；</li><li>对 key 进行哈希，映射到区间上，沿着环顺时针寻找并将其分配到距其最近的 slot；</li></ol><p>举个例子，假设现在有 N0, N1, N2 三个 slot 以及 a, b, c 三个 key，其中 a 会被分配 N1 上，b 和 c 都会被分配到 N2 上；</p><p><img alt=hash-ring-add-1 loading=lazy src=https://raw.githubusercontent.com/chr1sc2y/warehouse-deprecated/refs/heads/main/resources/consistent-hashing/hash-ring-add-1.png></p><p>现在我们<strong>新增</strong>一个 N3 slot，并将其映射到 [a, N1] 之间，那么 a 和<strong>所有在 [N0, N3] 之间的 key 都会被重新分配到 N3 这个 slot 上，除此之外的其他所有 key 则不会被重新映射</strong>；</p><p><img alt=hash-ring-add-2 loading=lazy src=https://raw.githubusercontent.com/chr1sc2y/warehouse-deprecated/refs/heads/main/resources/consistent-hashing/hash-ring-add-2.png></p><p>假设我们<strong>移除</strong> N2 slot，那么<strong>所有在 [N1, N2] 之间的 key 都会被重新映射到 N0 上，除此之外的其他所有 key 则不会被重新映射</strong>。</p><p>可以发现，ketama 算法达成了在新增或移除 slot 后的<strong>增量式重新映射</strong>（minimum disruption），不会破坏大多数 key 的映射关系；因为要构造出一个环来存储所有 slot 的 key 被映射到的位置，所以其空间复杂度是 O(n)；为了方便地进行查找，可以将环转换成一个有序数组，在其中进行二分查找，时间复杂度是 O(logn)。</p><h4 id=虚拟节点>虚拟节点<a hidden class=anchor aria-hidden=true href=#虚拟节点>#</a></h4><p>有时候我们可能会对不同的节点赋予不同的权重，也就导致了每个节点的地位不平等，从而不能直接将节点放在环上，解决方案是使用不同数量的虚拟节点（virtual node）来代表实际的节点，一般来说每个虚拟节点代表一个单位节点，虚拟节点数量之和等于实际节点的权重；即使不同节点之间的权重相同，也建议将一个实际节点映射为多个虚拟节点，因为节点越多，它们在环上的分布就越均匀，因此使用虚拟节点还可以降低节点之间的负载差异；假设 N0, N1, N2 三个节点具有相同的权重，那么用虚拟节点代替之后则大致如图：</p><p><img alt=virtual-slot loading=lazy src=https://raw.githubusercontent.com/chr1sc2y/warehouse-deprecated/refs/heads/main/resources/consistent-hashing/virtual-slot.png></p><h3 id=32-jump-consistent-hashing>3.2 Jump Consistent Hashing<a hidden class=anchor aria-hidden=true href=#32-jump-consistent-hashing>#</a></h3><p><a href=https://arxiv.org/abs/1406.2294>Jump Consistent Hashing</a> 跳跃一致性哈希是 Google 发表的一个非常简洁的一致性哈希算法，其主要思路是：</p><ol><li>假设有 n 个 slot 和 k 个 key，所有的 k 个 key 都被均匀地映射到了这 n 个 slot 上；</li><li>现在增加 1 个 slot，为了将原有的 k 个 key 均匀地映射到 n + 1 个 slot 上，需要将其中 k / n + 1 个 key 进行重新映射，即每次增加 1 个 slot 都需要重新映射 k / n + 1 个 key；</li><li>使用**<a href=https://en.wikipedia.org/wiki/Pseudorandom_number_generator>伪随机</a>**的方式（给定一个随机种子，生成一个固定的随机序列）来决定哪 k / n 个 key 需要被重新映射；</li></ol><p>这里使用伪随机的含义是，对于每一个 key，我们使用这个 key 来作为随机种子，生成一个固定的随机序列 seq，于是 seq 在其下标为 [1, n] 的区间里的值都是固定的；接下来遍历 seq，在每一次迭代 i 中，如果 seq[i] &lt; 1/i，则将其重新分配到第 i 个 slot 上，否则保持不变；整个过程在给定 key 时就已经确定了。</p><p><img alt=jump-consistent-hashing-0 loading=lazy src=https://raw.githubusercontent.com/chr1sc2y/warehouse-deprecated/refs/heads/main/resources/consistent-hashing/jump-consistent-hashing-0.png></p><p>这样一来就达成了一致性哈希的平衡性和单调性，没有使用额外的内存，所以空间复杂度是 O(1)；而因为遍历了 n 个 slot，所以时间复杂度是 O(n)，还可以从时间复杂度的角度继续优化；在 seq[i] &lt; 1 / i 这个公式中（即被重新分配这个假设成立），1 / i 会随着 i 的增大而变得越来越小，而 seq[i] 是随机数，因此可以认为公式成立的概率会越来越小，所以我们可以让 i 的步进增大，来减少迭代的次数。</p><p>假设当前 key 所在的 slot 是 b，迭代次数是 b + 1 ，下一次迭代某一个 key 会被重新映射的概率是 1 / b + 2（上面思路第 2 点），即其不会被重新分配到新 slot 的概率为 b + 1 / b + 2，再下一次的概率是 b + 2 / b + 3，直到第 j 次的概率是 j - 1 / j，将这些概率相乘得到在这 j - b 次之间 key 不会被重新分配的概率是 b + 1 / j；假设把 seq[i] 用 r = random.next() 来表示，要使得 r &lt; (b + 1) / j（即被重新分配这个假设成立），就必须有 j &lt; (b + 1) / r，那么 key 在步进大于等于 (b + 1) / r 次后一定会被重新分配。</p><p><img alt=jump-consistent-hashing-1 loading=lazy src=https://raw.githubusercontent.com/chr1sc2y/warehouse-deprecated/refs/heads/main/resources/consistent-hashing/jump-consistent-hashing-1.png></p><p>这样一来时间复杂度就减少到了 O(ln(n))；但其局限性也很明显，因为只能通过步进的方式来重新映射和分配 slot，导致其只能在尾部增删 slot，否则在中间进行增删的话会导致其后续的 slot 下标和步进关系都发生变化，</p><p>论文中还对比了其与哈希环法的运行时间。</p><p><img alt=karger loading=lazy src=https://raw.githubusercontent.com/chr1sc2y/warehouse-deprecated/refs/heads/main/resources/consistent-hashing/karger.png></p><h3 id=33-maglev-hashing>3.3 Maglev Hashing<a hidden class=anchor aria-hidden=true href=#33-maglev-hashing>#</a></h3><p><a href=https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/44824.pdf>Maglev</a> 是 Google 研发的一个负载均衡组件，使用了其自研的一致性哈希算法 Maglev Hashing，其主要思路是通过维护两个 table 来将 key 映射到 slot 上；一个表是 lookup table 查找表，用于将 key 映射到 slot 上；另一个表是 permutation table 排列表，用于记录一个 slot 在 lookup table 中的位置序列：</p><p><img alt=maglev-table loading=lazy src=https://raw.githubusercontent.com/chr1sc2y/warehouse-deprecated/refs/heads/main/resources/consistent-hashing/maglev-table.png></p><p>对于 n 个 slot 和一个长度为 m 的映射序列（即 permutation table 和 lookup table 的长度），我们希望为每一个下标为 i 的 slot 都计算出一个数量为 m 的排列，计算时需要使用两个<strong>不同的哈希函数</strong> h1 和 h2，来计算 offset 和 skip 两个值（这里需要保证每一个 slot 的 name 都不相同）：</p><p><img alt=permutation loading=lazy src=https://raw.githubusercontent.com/chr1sc2y/warehouse-deprecated/refs/heads/main/resources/consistent-hashing/permutation.png></p><p>举个例子，假设 n = 3，m = 7，对于下标为 0 的 slot，通过某两个哈希函数计算出来的 offset = 3，skip = 4，为其生成一个长度 m = 7 的 permutation：</p><pre tabindex=0><code>permutation[i][0] = (3 + 0 * 4) mod 7 = 3
permutation[i][1] = (3 + 1 * 4) mod 7 = 0
permutation[i][2] = (3 + 2 * 4) mod 7 = 4
permutation[i][3] = (3 + 3 * 4) mod 7 = 1
permutation[i][4] = (3 + 4 * 4) mod 7 = 5
permutation[i][5] = (3 + 5 * 4) mod 7 = 2
permutation[i][6] = (3 + 6 * 4) mod 7 = 6
</code></pre><p>再加上另外两个计算好 permutation 的下标为 1 和 2 的 slot，对应的 permutation table：</p><table><thead><tr><th>m</th><th>s0</th><th>s1</th><th>s2</th></tr></thead><tbody><tr><td>0</td><td>3</td><td>0</td><td>3</td></tr><tr><td>1</td><td>0</td><td>2</td><td>4</td></tr><tr><td>2</td><td>4</td><td>4</td><td>5</td></tr><tr><td>3</td><td>1</td><td>6</td><td>6</td></tr><tr><td>4</td><td>5</td><td>1</td><td>0</td></tr><tr><td>5</td><td>2</td><td>3</td><td>1</td></tr><tr><td>6</td><td>6</td><td>5</td><td>2</td></tr></tbody></table><p>现在我们让 3 个 slot 轮流地从其 permutation 中，按顺序选择第一个没有被分配的 key，来填充到之后的 lookup table 中，流程是：</p><ol><li>s0 的 permutation 中的第一个数字 3 没有被分配，选择 3；</li><li>s1 的 permutation 中的第一个数字 0 没有被分配，选择 0；</li><li>s2 的 permutation 中的第一个数字 3 已经被分配了，往后遍历到数字 4，选择 4；</li><li>s0 在 permutation 中往后遍历，0 和 4 都已经被分配了，选择 1；</li><li>s1 在 permutation 中往后遍历，选择 2；</li><li>s2 在 permutation 中往后遍历，4 已经被分配了，选择 5；</li><li>s0 在 permutation 中往后遍历直到选择 6；</li></ol><p>于是就有了 lookup table：</p><table><thead><tr><th>m</th><th>slot</th></tr></thead><tbody><tr><td>0</td><td>s1</td></tr><tr><td>1</td><td>s0</td></tr><tr><td>2</td><td>s1</td></tr><tr><td>3</td><td>s0</td></tr><tr><td>4</td><td>s2</td></tr><tr><td>5</td><td>s2</td></tr><tr><td>6</td><td>s0</td></tr></tbody></table><p>这种方法类似于开放寻址法中的双重哈希，通过使用两个无关的哈希函数来生成排列（也可以使用其他生成随机排列的方法，例如 <a href=https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle>fisher-yates shuffle</a>，必须保证方法的的随机性）降低了哈希碰撞的概率；在增加或移除 slot 时，需要为新的 slot 生成 permutation table，再重新生成 lookup table，这会导致部分重新映射，不满足最小化重新映射（minimum disruption）；维护两个表的空间复杂度是 O(n)，查询的时间复杂度是 O(1)；建立表的复杂度可以参考论文的第 3.4 节。</p><p><img alt=minimal-disruption loading=lazy src=https://raw.githubusercontent.com/chr1sc2y/warehouse-deprecated/refs/heads/main/resources/consistent-hashing/minimal-disruption.png></p><h2 id=4-总结>4 总结<a hidden class=anchor aria-hidden=true href=#4-总结>#</a></h2><p>本文主要介绍了负载均衡的概念，并简单地阐明了一致性哈希算法的原理，关于一致性哈希算法的优缺点、边界条件、复杂度分析、效率对比、实际应用等还需要结合论文和开源组件进行更深入的了解。</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://prov1dence.top/posts/cpp/closure-and-anonymous-function/><span class=title>« Prev</span><br><span>C++ 闭包和匿名函数</span>
</a><a class=next href=https://prov1dence.top/posts/cpp/concurrency/introduction-to-concurrency/><span class=title>Next »</span><br><span>C++ 并发入门：以 LeetCode 1114 为例</span></a></nav></footer></article></main><footer class=footer></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>