<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Redis 持久化机制: RDB 和 AOF | ChrisChen - 尾張</title>
<meta name=keywords content><meta name=description content="Redis 持久化机制: RDB 和 AOF
Redis 持久化
为什么需要持久化?
Redis 是基于内存的数据库, 服务一旦宕机, 内存中的数据将全部丢失. 通常来说可以通过数据库来恢复这些数据, 但这会给数据库带来非常大的读压力, 并且这个过程会非常缓慢, 并导致程序响应慢, 因此 Redis 提供了把内存数据持久化到硬盘, 并通过备份文件来恢复数据的功能, 即持久化机制.
持久化的方式
目前 Redis Documentation 上对持久化的支持有以下几种方案:

RDB (Redis Database): 将某个时间点上的数据生成快照 (snapshot) 并保存到硬盘上
AOF (Append Only File): 将每个接收到的写操作记录到硬盘上, 这些操作可以在 Redis 重启时被重放, 并用于重新构建 Redis 数据库
RDB + AOF: AOF 和 RDB 的混合模式

RDB
RDB 指对整个数据集在特定时间点生成快照 (point-to-time snapshot), 可用于Redis的数据备份, 转移和恢复. 它是 Redis 默认使用的持久化方案.
工作原理
RDB 利用操作系统提供的写时复制 (Copy-on-Write) 机制来进行持久化, 即当主进程 P fork 出子进程时 Q 时, Q 和 P 共享同一块内存空间, 当 P 准备对某块内存进行写操作时, P 会将这块内存页进行复制, 并在新的副本上对数据进行修改, 而 Q 仍然读取原先的内存页. 这样既能够保证 Redis 实例继续服务外部流量, 又能够以最小的成本完成数据的持久化. 但正因如此, 持久化过程中的写操作是不会被记录的."><meta name=author content><link rel=canonical href=https://prov1dence.top/posts/data/redis-%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6-rdb-%E5%92%8C-aof-72a88c70207a4518824d1fe4be7ebb9e/><link crossorigin=anonymous href=/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as=style><link rel=icon href=https://prov1dence.top/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://prov1dence.top/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://prov1dence.top/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://prov1dence.top/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://prov1dence.top/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://prov1dence.top/posts/data/redis-%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6-rdb-%E5%92%8C-aof-72a88c70207a4518824d1fe4be7ebb9e/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://prov1dence.top/posts/data/redis-%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6-rdb-%E5%92%8C-aof-72a88c70207a4518824d1fe4be7ebb9e/"><meta property="og:site_name" content="ChrisChen - 尾張"><meta property="og:title" content="Redis 持久化机制: RDB 和 AOF"><meta property="og:description" content="Redis 持久化机制: RDB 和 AOF Redis 持久化 为什么需要持久化? Redis 是基于内存的数据库, 服务一旦宕机, 内存中的数据将全部丢失. 通常来说可以通过数据库来恢复这些数据, 但这会给数据库带来非常大的读压力, 并且这个过程会非常缓慢, 并导致程序响应慢, 因此 Redis 提供了把内存数据持久化到硬盘, 并通过备份文件来恢复数据的功能, 即持久化机制.
持久化的方式 目前 Redis Documentation 上对持久化的支持有以下几种方案:
RDB (Redis Database): 将某个时间点上的数据生成快照 (snapshot) 并保存到硬盘上 AOF (Append Only File): 将每个接收到的写操作记录到硬盘上, 这些操作可以在 Redis 重启时被重放, 并用于重新构建 Redis 数据库 RDB + AOF: AOF 和 RDB 的混合模式 RDB RDB 指对整个数据集在特定时间点生成快照 (point-to-time snapshot), 可用于Redis的数据备份, 转移和恢复. 它是 Redis 默认使用的持久化方案.
工作原理 RDB 利用操作系统提供的写时复制 (Copy-on-Write) 机制来进行持久化, 即当主进程 P fork 出子进程时 Q 时, Q 和 P 共享同一块内存空间, 当 P 准备对某块内存进行写操作时, P 会将这块内存页进行复制, 并在新的副本上对数据进行修改, 而 Q 仍然读取原先的内存页. 这样既能够保证 Redis 实例继续服务外部流量, 又能够以最小的成本完成数据的持久化. 但正因如此, 持久化过程中的写操作是不会被记录的."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-02-01T18:02:04+11:00"><meta property="article:modified_time" content="2023-02-01T18:02:04+11:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Redis 持久化机制: RDB 和 AOF"><meta name=twitter:description content="Redis 持久化机制: RDB 和 AOF
Redis 持久化
为什么需要持久化?
Redis 是基于内存的数据库, 服务一旦宕机, 内存中的数据将全部丢失. 通常来说可以通过数据库来恢复这些数据, 但这会给数据库带来非常大的读压力, 并且这个过程会非常缓慢, 并导致程序响应慢, 因此 Redis 提供了把内存数据持久化到硬盘, 并通过备份文件来恢复数据的功能, 即持久化机制.
持久化的方式
目前 Redis Documentation 上对持久化的支持有以下几种方案:

RDB (Redis Database): 将某个时间点上的数据生成快照 (snapshot) 并保存到硬盘上
AOF (Append Only File): 将每个接收到的写操作记录到硬盘上, 这些操作可以在 Redis 重启时被重放, 并用于重新构建 Redis 数据库
RDB + AOF: AOF 和 RDB 的混合模式

RDB
RDB 指对整个数据集在特定时间点生成快照 (point-to-time snapshot), 可用于Redis的数据备份, 转移和恢复. 它是 Redis 默认使用的持久化方案.
工作原理
RDB 利用操作系统提供的写时复制 (Copy-on-Write) 机制来进行持久化, 即当主进程 P fork 出子进程时 Q 时, Q 和 P 共享同一块内存空间, 当 P 准备对某块内存进行写操作时, P 会将这块内存页进行复制, 并在新的副本上对数据进行修改, 而 Q 仍然读取原先的内存页. 这样既能够保证 Redis 实例继续服务外部流量, 又能够以最小的成本完成数据的持久化. 但正因如此, 持久化过程中的写操作是不会被记录的."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://prov1dence.top/posts/"},{"@type":"ListItem","position":2,"name":"Redis 持久化机制: RDB 和 AOF","item":"https://prov1dence.top/posts/data/redis-%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6-rdb-%E5%92%8C-aof-72a88c70207a4518824d1fe4be7ebb9e/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Redis 持久化机制: RDB 和 AOF","name":"Redis 持久化机制: RDB 和 AOF","description":"Redis 持久化机制: RDB 和 AOF Redis 持久化 为什么需要持久化? Redis 是基于内存的数据库, 服务一旦宕机, 内存中的数据将全部丢失. 通常来说可以通过数据库来恢复这些数据, 但这会给数据库带来非常大的读压力, 并且这个过程会非常缓慢, 并导致程序响应慢, 因此 Redis 提供了把内存数据持久化到硬盘, 并通过备份文件来恢复数据的功能, 即持久化机制.\n持久化的方式 目前 Redis Documentation 上对持久化的支持有以下几种方案:\nRDB (Redis Database): 将某个时间点上的数据生成快照 (snapshot) 并保存到硬盘上 AOF (Append Only File): 将每个接收到的写操作记录到硬盘上, 这些操作可以在 Redis 重启时被重放, 并用于重新构建 Redis 数据库 RDB + AOF: AOF 和 RDB 的混合模式 RDB RDB 指对整个数据集在特定时间点生成快照 (point-to-time snapshot), 可用于Redis的数据备份, 转移和恢复. 它是 Redis 默认使用的持久化方案.\n工作原理 RDB 利用操作系统提供的写时复制 (Copy-on-Write) 机制来进行持久化, 即当主进程 P fork 出子进程时 Q 时, Q 和 P 共享同一块内存空间, 当 P 准备对某块内存进行写操作时, P 会将这块内存页进行复制, 并在新的副本上对数据进行修改, 而 Q 仍然读取原先的内存页. 这样既能够保证 Redis 实例继续服务外部流量, 又能够以最小的成本完成数据的持久化. 但正因如此, 持久化过程中的写操作是不会被记录的.\n","keywords":[],"articleBody":"Redis 持久化机制: RDB 和 AOF Redis 持久化 为什么需要持久化? Redis 是基于内存的数据库, 服务一旦宕机, 内存中的数据将全部丢失. 通常来说可以通过数据库来恢复这些数据, 但这会给数据库带来非常大的读压力, 并且这个过程会非常缓慢, 并导致程序响应慢, 因此 Redis 提供了把内存数据持久化到硬盘, 并通过备份文件来恢复数据的功能, 即持久化机制.\n持久化的方式 目前 Redis Documentation 上对持久化的支持有以下几种方案:\nRDB (Redis Database): 将某个时间点上的数据生成快照 (snapshot) 并保存到硬盘上 AOF (Append Only File): 将每个接收到的写操作记录到硬盘上, 这些操作可以在 Redis 重启时被重放, 并用于重新构建 Redis 数据库 RDB + AOF: AOF 和 RDB 的混合模式 RDB RDB 指对整个数据集在特定时间点生成快照 (point-to-time snapshot), 可用于Redis的数据备份, 转移和恢复. 它是 Redis 默认使用的持久化方案.\n工作原理 RDB 利用操作系统提供的写时复制 (Copy-on-Write) 机制来进行持久化, 即当主进程 P fork 出子进程时 Q 时, Q 和 P 共享同一块内存空间, 当 P 准备对某块内存进行写操作时, P 会将这块内存页进行复制, 并在新的副本上对数据进行修改, 而 Q 仍然读取原先的内存页. 这样既能够保证 Redis 实例继续服务外部流量, 又能够以最小的成本完成数据的持久化. 但正因如此, 持久化过程中的写操作是不会被记录的.\n触发方式 触发rdb持久化的方式有2种:\n手动触发. 包含两个命令: save: 阻塞 Redis 进程, 并进行 RDB 持久化, 直到其完成为止, 对于内存占用大的实例会造成长时间阻塞. bgsave: background save, 让 Redis 进程通过 fork 操作创建子进程, 并在子进程进行 RDB 持久化, 只在 fork 阶段阻塞 Redis 进程 自动触发, 通过配置中的 save 命令实现. Redis 服务有一个周期性维护函数 serverCron, 默认每 100 ms 执行一次, 它的其中一项功能就是检查所有 save 命令的条件里是否有任意一条被满足. 如果不想使用自动触发, 把所有的 save 命令注释即可. save x y # 在 x 秒内如果至少有 y 个 key 值发生变化, 则触发RDB save 60 900 # 在 60 秒内如果至少有 900 个 key 值发生变化, 则触发RDB 总结 是否应该以尽可能高的频率来触发 RDB? 为了保证宕机时丢失的数据尽量少, 我们也许可以每分钟出发一次 RDB 进行数据备份. 虽然 bgsave 在子进程中执行, 不会阻塞主线程, 但仍然有一些问题：\nbgsave 需要通过 fork 操作来创建子进程, fork 操作本身是会阻塞主进程的, 并且主线程占用内存越多, fork 操作的阻塞时间越长 将全量数据写入硬盘的操作会占用大量的带宽, 给硬盘带来很大的压力, 从而影响 Redis 实例的性能, 并且如果上一次的写入操作尚未完成, 就开始了下一次的写入操作, 更有可能会造成恶性循环 从这两点出发可以认为触发 RDB 的频率并不是越高越好, 我们需要考虑 Redis 实例占用内存的大小以及全量数据写入硬盘的速度.\n优点 RDB文件是某个时间节点的快照, 默认使用 LZF 算法进行压缩, 压缩后的文件体积远远小于内存大小, 适用于定期执行（例如每一小时进行一次）, 并将 RDB 文件上传到数据中心进行容灾备份 与AOF相比, 使用 RDB 恢复大型数据集更快 缺点 RDB 方式实时性不够, 无法做到秒级的持久化； RDB 需要 fork 子进程, 而 fork 进程执行成本非常高； RDB 文件是二进制编码的, 没有可读性 AOF AOF (Append Only File) 通过写日志的方式, 在 Redis 每次写操作完成后在日志里记录下此次执行的命令, 当服务器重启的时候通过顺序地重放这些日志来恢复数据.\n配置\nAOF 功能默认是关闭的, 需要通过修改 redis.conf 并重启 Redis 来开启.\n# no by default appendonly yes appendfilename appendonly.aof 写后日志\n和 MySQL 的写前日志 (Write-Ahead Logging) 不同, AOF 会在写操作完成后记录日志, 这样既能够保证 Redis 不阻塞并及时响应写操作, 还可以避免运行时检查出写操作命令不合法再回滚这条日志. 但如果在命令执行完之后, 写日志完成之前, 服务器发生了宕机, 也有可能会丢失数据.\n工作流程\nAOF的工作原理可以概括为几个步骤：命令追加（append）、文件写入与同步（fsync）、文件重写（rewrite）、重启加载（load）.\n1 追加命令 append 当 AOF 持久化功能开启时, Redis 执行完一个写命令后, 会按照 RESP (Redis Serialization Protocol) 协议规定的格式把这条写命令追加到其维护的 AOF 缓冲区末尾.\nAOF缓冲区 (aof_buf) 采用 Redis 特有的数据结构 SDS (Simple Dynamic String), 根据命令的类型, 使用不同的方法（catAppendOnlyGenericCommand, catAppendOnlyExpireAtCommand等）, 来对命令进行处理, 最后写入缓冲区.\n如果命令追加时正在进行 AOF 重写, 这些命令还会追加到重写缓冲区 aof_rewrite_buffer.\n2 写入文件以及同步 fsync 由于硬盘的 I/O 性能较差, 文件读写速度远远比不上 CPU 的处理速度, 那么如果每次文件写入都等待数据写入硬盘, 会整体拉低操作系统的性能. 为了解决这个问题, 操作系统提供了**延迟写（delayed write）**机制来提高硬盘的I/O性能.\nRedis 每次事件轮询结束前（beforeSleep）都会调用函数 flushAppendOnlyFile, 它会把 AOF 缓冲区中的数据写入内核缓冲区, 并且根据 appendfsync 的配置来决定采用何种策略把内核缓冲区中的数据写入磁盘, 即调用 fsync() , 有三个可选项：\nalways：每次都调用fsync(), 安全性最高, 但性能最差 no：不会调用fsync(). 性能最好, 安全性最差. everysec：仅在满足同步条件时调用fsync(). 这是官方推荐的策略, 也是默认配置, 能够兼顾性能和数据安全性, 只有在系统突然宕机的情况下会丢失 1 秒的数据. 3 重写 rewrite 随着时间的增加, AOF 文件体积会越来越大, 导致磁盘占用空间更多, 数据恢复时间更长. 为了解决这个问题, Redis 引入了 AOF 重写 (AOF Rewrite) 机制, 通过创建新的 AOF 文件, 将旧文件中的多条命令整合成为新文件中的单条命令, 并替换旧文件, 来减少 AOF 文件的体积.\n重写在何时发生? 和 RDB 的触发方式类似, AOF重写可以通过手动或自动触发.\n手动触发：调用bgrewriteaof命令, 如果当前不存在正在执行的 bgsave 或 bgrewriteaof 子进程, 那么重写会立即执行, 否则会等待子进程操作结束后再执行. 自动触发由两个配置项控制, 只有这两个指标同时满足的时候才会发生重写： auto-aof-rewrite-percentage: 当前AOF文件（aof_current_size）和上一次重写发生后AOF文件大小（aof_base_size）相比, 其增加的比例, 默认为100, 即当 aof_current_size == 2 * aof_base_size 时触发 auto-aof-rewrite-min-size: 运行BGREWRITEAOF时AOF文件占用空间最小值, 默认为64MB 重写的流程是怎么样的? bgrewriteaof 触发重写, 判断是否存在 bgsave 或者 bgrewriteaof 正在执行, 如果存在则等待其执行结束再执行 主进程fork子进程, 防止主进程阻塞无法提供服务 子进程遍历 Redis 内存快照中数据写入临时 AOF 文件, 同时会将新的写指令写入 aof_buf 和 aof_rewrite_buf 两个重写缓冲区, 前者是为了写回旧的 AOF 文件, 后者是为了后续刷新到临时 AOF 文件中, 防止快照内存遍历时新的写入操作丢失 子进程结束临时AOF文件写入后, 通知主进程 主进程会将 aof_rewirte_buf 中的数据写到子进程生成的临时 AOF log 中 主进程使用临时AOF文件替换旧AOF文件, 完成整个重写过程 整个过程可以参考下图：\nRedis启动时把aof_base_size初始化为当时aof文件的大小, Redis运行过程中, 当AOF文件重写操作完成时, 会对其进行更新；aof_current_size为serverCron执行时AOF文件的实时大小. 当满足以下两个条件时, AOF文件重写就会触发：\nAOF重写会阻塞吗? AOF 的重写过程是由后台进程 bgrewriteaof 来完成的. 主线程 fork 出后台的 bgrewriteaof 子进程, fork 操作会把主线程的内存拷贝一份给 bgrewriteaof 子进程, 这里面就包含了数据库的最新数据. 然后, bgrewriteaof 子进程逐一把拷贝的数据写成操作, 并记入重写日志, 因此在重写过程中, 只有当 fork 操作发生时会阻塞主线程.\n4 重启并加载 load Redis启动后通过loadDataFromDisk函数执行数据加载, 流程大致如下：\n未开启 AOF 的情况下, 只使用 RDB 文件加载数据 开启 AOF 的情况下, 如果 AOF 文件使用 RDB 头, 那么先使用 RDB, 再使用 AOF , 否则只使用 AOF 加载数据 总结 AOF能保证数据完整性么? 如果在对AOF文件进行写操作时发生了宕机, 或磁盘满了, 由于延迟写的特点, AOF的RESP命令可能会因为被截断而不完整. 发生这种情况时, Redis会按照配置项aof-load-truncated 的值来进行不同的操作：\nyes：尽可能多的加载数据, 并以日志的方式通知用户； no：以系统错误的方式产生崩溃, 并禁止重启, 需要用户手动修复文件 优点 AOF持久化有更好的实时性, 因为使用 every second 作为 fsyn从的默认策略, 极端情况下可能只会丢失一秒的数据 对 AOF log 的操作只有 append, 不会导致文件损坏；即使最后写入数据被截断, 也很容易使用redis-check-aof工具修复 重写机制可以保证 AOF log 不占用太大空间, 并且重写过程中新的写操作也会记录到旧的 log 中, 防止数据丢失 AOF log 具有更高的可读性, 并且可以轻易导出 缺点 对于相同的数据集, AOF 文件通常会比 RDB 文件大 在写操作较多时, AOF 的延迟会更高 Reference https://redis.io/docs/management/persistence/\n","wordCount":"544","inLanguage":"en","datePublished":"2023-02-01T18:02:04+11:00","dateModified":"2023-02-01T18:02:04+11:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://prov1dence.top/posts/data/redis-%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6-rdb-%E5%92%8C-aof-72a88c70207a4518824d1fe4be7ebb9e/"},"publisher":{"@type":"Organization","name":"ChrisChen - 尾張","logo":{"@type":"ImageObject","url":"https://prov1dence.top/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://prov1dence.top/ accesskey=h title="尾張 (Alt + H)">尾張</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://prov1dence.top/archives/ title=Posts><span>Posts</span></a></li><li><a href=https://prov1dence.top/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Redis 持久化机制: RDB 和 AOF</h1><div class=post-meta><span title='2023-02-01 18:02:04 +1100 AEDT'>February 1, 2023</span>&nbsp;·&nbsp;3 min</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#redis-%e6%8c%81%e4%b9%85%e5%8c%96%e6%9c%ba%e5%88%b6-rdb-%e5%92%8c-aof aria-label="Redis 持久化机制: RDB 和 AOF">Redis 持久化机制: RDB 和 AOF</a></li><li><a href=#redis-%e6%8c%81%e4%b9%85%e5%8c%96 aria-label="Redis 持久化">Redis 持久化</a><ul><ul><li><a href=#%e4%b8%ba%e4%bb%80%e4%b9%88%e9%9c%80%e8%a6%81%e6%8c%81%e4%b9%85%e5%8c%96 aria-label=为什么需要持久化?>为什么需要持久化?</a></li><li><a href=#%e6%8c%81%e4%b9%85%e5%8c%96%e7%9a%84%e6%96%b9%e5%bc%8f aria-label=持久化的方式>持久化的方式</a></li></ul></ul></li><li><a href=#rdb aria-label=RDB>RDB</a><ul><li><a href=#%e5%b7%a5%e4%bd%9c%e5%8e%9f%e7%90%86 aria-label=工作原理>工作原理</a></li><li><a href=#%e8%a7%a6%e5%8f%91%e6%96%b9%e5%bc%8f aria-label=触发方式>触发方式</a></li><li><a href=#%e6%80%bb%e7%bb%93 aria-label=总结>总结</a><ul><li><a href=#%e6%98%af%e5%90%a6%e5%ba%94%e8%af%a5%e4%bb%a5%e5%b0%bd%e5%8f%af%e8%83%bd%e9%ab%98%e7%9a%84%e9%a2%91%e7%8e%87%e6%9d%a5%e8%a7%a6%e5%8f%91-rdb aria-label="是否应该以尽可能高的频率来触发 RDB?">是否应该以尽可能高的频率来触发 RDB?</a></li><li><a href=#%e4%bc%98%e7%82%b9 aria-label=优点>优点</a></li><li><a href=#%e7%bc%ba%e7%82%b9 aria-label=缺点>缺点</a></li></ul></li></ul></li><li><a href=#aof aria-label=AOF>AOF</a><ul><li><a href=#1-%e8%bf%bd%e5%8a%a0%e5%91%bd%e4%bb%a4-append aria-label="1 追加命令 append">1 追加命令 append</a></li><li><a href=#2-%e5%86%99%e5%85%a5%e6%96%87%e4%bb%b6%e4%bb%a5%e5%8f%8a%e5%90%8c%e6%ad%a5-fsync aria-label="2 写入文件以及同步 fsync">2 写入文件以及同步 fsync</a></li><li><a href=#3-%e9%87%8d%e5%86%99-rewrite aria-label="3 重写 rewrite">3 重写 rewrite</a><ul><li><a href=#%e9%87%8d%e5%86%99%e5%9c%a8%e4%bd%95%e6%97%b6%e5%8f%91%e7%94%9f aria-label=重写在何时发生?>重写在何时发生?</a></li><li><a href=#%e9%87%8d%e5%86%99%e7%9a%84%e6%b5%81%e7%a8%8b%e6%98%af%e6%80%8e%e4%b9%88%e6%a0%b7%e7%9a%84 aria-label=重写的流程是怎么样的?>重写的流程是怎么样的?</a></li><li><a href=#aof%e9%87%8d%e5%86%99%e4%bc%9a%e9%98%bb%e5%a1%9e%e5%90%97 aria-label=AOF重写会阻塞吗?>AOF重写会阻塞吗?</a></li></ul></li><li><a href=#4-%e9%87%8d%e5%90%af%e5%b9%b6%e5%8a%a0%e8%bd%bd-load aria-label="4 重启并加载 load">4 重启并加载 load</a></li><li><a href=#%e6%80%bb%e7%bb%93-1 aria-label=总结>总结</a><ul><li><a href=#aof%e8%83%bd%e4%bf%9d%e8%af%81%e6%95%b0%e6%8d%ae%e5%ae%8c%e6%95%b4%e6%80%a7%e4%b9%88 aria-label=AOF能保证数据完整性么?>AOF能保证数据完整性么?</a></li><li><a href=#%e4%bc%98%e7%82%b9-1 aria-label=优点>优点</a></li><li><a href=#%e7%bc%ba%e7%82%b9-1 aria-label=缺点>缺点</a></li></ul></li></ul></li><li><a href=#reference aria-label=Reference>Reference</a></li></ul></div></details></div><div class=post-content><h1 id=redis-持久化机制-rdb-和-aof>Redis 持久化机制: RDB 和 AOF<a hidden class=anchor aria-hidden=true href=#redis-持久化机制-rdb-和-aof>#</a></h1><h1 id=redis-持久化>Redis 持久化<a hidden class=anchor aria-hidden=true href=#redis-持久化>#</a></h1><h3 id=为什么需要持久化>为什么需要持久化?<a hidden class=anchor aria-hidden=true href=#为什么需要持久化>#</a></h3><p>Redis 是基于内存的数据库, 服务一旦宕机, 内存中的数据将全部丢失. 通常来说可以通过数据库来恢复这些数据, 但这会给数据库带来非常大的读压力, 并且这个过程会非常缓慢, 并导致程序响应慢, 因此 Redis 提供了把内存数据持久化到硬盘, 并通过备份文件来恢复数据的功能, 即持久化机制.</p><h3 id=持久化的方式>持久化的方式<a hidden class=anchor aria-hidden=true href=#持久化的方式>#</a></h3><p>目前 <a href=https://redis.io/docs/management/persistence/>Redis Documentation</a> 上对持久化的支持有以下几种方案:</p><ol><li>RDB (Redis Database): 将某个时间点上的数据生成快照 (snapshot) 并保存到硬盘上</li><li>AOF (Append Only File): 将每个接收到的写操作记录到硬盘上, 这些操作可以在 Redis 重启时被重放, 并用于重新构建 Redis 数据库</li><li>RDB + AOF: AOF 和 RDB 的混合模式</li></ol><h1 id=rdb>RDB<a hidden class=anchor aria-hidden=true href=#rdb>#</a></h1><p>RDB 指对整个数据集在特定时间点生成快照 (point-to-time snapshot), 可用于Redis的数据备份, 转移和恢复. 它是 Redis 默认使用的持久化方案.</p><h2 id=工作原理>工作原理<a hidden class=anchor aria-hidden=true href=#工作原理>#</a></h2><p>RDB 利用操作系统提供的<a href=https://en.wikipedia.org/wiki/Copy-on-write>写时复制</a> (Copy-on-Write) 机制来进行持久化, 即当主进程 P fork 出子进程时 Q 时, Q 和 P 共享同一块内存空间, 当 P 准备对某块内存进行写操作时, P 会将这块内存页进行复制, 并在新的副本上对数据进行修改, 而 Q 仍然读取原先的内存页. 这样既能够保证 Redis 实例继续服务外部流量, 又能够以最小的成本完成数据的持久化. 但正因如此, 持久化过程中的写操作是不会被记录的.</p><p><img alt=1 loading=lazy src=https://raw.githubusercontent.com/chr1sc2y/prov1dence.github.io/refs/heads/master/posts/data/1.png/></p><p><img alt=2 loading=lazy src=https://raw.githubusercontent.com/chr1sc2y/prov1dence.github.io/refs/heads/master/posts/data/2.png/></p><h2 id=触发方式>触发方式<a hidden class=anchor aria-hidden=true href=#触发方式>#</a></h2><p>触发rdb持久化的方式有2种:</p><ol><li>手动触发. 包含两个命令:<ol><li><code>save</code>: 阻塞 Redis 进程, 并进行 RDB 持久化, 直到其完成为止, 对于内存占用大的实例会造成长时间阻塞.</li><li><code>bgsave</code>: background save, 让 Redis 进程通过 fork 操作创建子进程, 并在子进程进行 RDB 持久化, 只在 fork 阶段阻塞 Redis 进程</li></ol></li><li>自动触发, 通过配置中的 save 命令实现. Redis 服务有一个周期性维护函数 <code>serverCron</code>, 默认每 100 ms 执行一次, 它的其中一项功能就是检查所有 save 命令的条件里是否有任意一条被满足. 如果不想使用自动触发, 把所有的 save 命令注释即可.</li></ol><pre tabindex=0><code>save x y # 在 x 秒内如果至少有 y 个 key 值发生变化, 则触发RDB
save 60 900 # 在 60 秒内如果至少有 900 个 key 值发生变化, 则触发RDB
</code></pre><h2 id=总结>总结<a hidden class=anchor aria-hidden=true href=#总结>#</a></h2><h3 id=是否应该以尽可能高的频率来触发-rdb>是否应该以尽可能高的频率来触发 RDB?<a hidden class=anchor aria-hidden=true href=#是否应该以尽可能高的频率来触发-rdb>#</a></h3><p>为了保证宕机时丢失的数据尽量少, 我们也许可以每分钟出发一次 RDB 进行数据备份. 虽然 bgsave 在子进程中执行, 不会阻塞主线程, 但仍然有一些问题：</p><ol><li>bgsave 需要通过 fork 操作来创建子进程, fork 操作本身是会阻塞主进程的, 并且主线程占用内存越多, fork 操作的阻塞时间越长</li><li>将全量数据写入硬盘的操作会占用大量的带宽, 给硬盘带来很大的压力, 从而影响 Redis 实例的性能, 并且如果上一次的写入操作尚未完成, 就开始了下一次的写入操作, 更有可能会造成恶性循环</li></ol><p>从这两点出发可以认为触发 RDB 的频率并不是越高越好, 我们需要考虑 Redis 实例占用内存的大小以及全量数据写入硬盘的速度.</p><h3 id=优点>优点<a hidden class=anchor aria-hidden=true href=#优点>#</a></h3><ul><li>RDB文件是某个时间节点的快照, 默认使用 LZF 算法进行压缩, 压缩后的文件体积远远小于内存大小, 适用于定期执行（例如每一小时进行一次）, 并将 RDB 文件上传到数据中心进行容灾备份</li><li>与AOF相比, 使用 RDB 恢复大型数据集更快</li></ul><h3 id=缺点>缺点<a hidden class=anchor aria-hidden=true href=#缺点>#</a></h3><ul><li>RDB 方式实时性不够, 无法做到秒级的持久化；</li><li>RDB 需要 fork 子进程, 而 fork 进程执行成本非常高；</li><li>RDB 文件是二进制编码的, 没有可读性</li></ul><h1 id=aof>AOF<a hidden class=anchor aria-hidden=true href=#aof>#</a></h1><p>AOF (Append Only File) 通过写日志的方式, 在 Redis 每次写操作完成后在日志里记录下此次执行的命令, 当服务器重启的时候通过顺序地重放这些日志来恢复数据.</p><p><strong>配置</strong></p><p>AOF 功能默认是关闭的, 需要通过修改 redis.conf 并重启 Redis 来开启.</p><pre tabindex=0><code># no by default
appendonly yes
appendfilename appendonly.aof
</code></pre><p><strong>写后日志</strong></p><p>和 MySQL 的写前日志 (Write-Ahead Logging) 不同, AOF 会在写操作完成后记录日志, 这样既能够保证 Redis 不阻塞并及时响应写操作, 还可以避免运行时检查出写操作命令不合法再回滚这条日志. 但如果在命令执行完之后, 写日志完成之前, 服务器发生了宕机, 也有可能会丢失数据.</p><p><strong>工作流程</strong></p><p>AOF的工作原理可以概括为几个步骤：命令追加（append）、文件写入与同步（fsync）、文件重写（rewrite）、重启加载（load）.</p><h2 id=1-追加命令-append>1 追加命令 append<a hidden class=anchor aria-hidden=true href=#1-追加命令-append>#</a></h2><p>当 AOF 持久化功能开启时, Redis 执行完一个写命令后, 会按照 <strong><a href=https://redis.io/docs/reference/protocol-spec/>RESP (Redis Serialization Protocol)</a></strong> 协议规定的格式把这条写命令<strong>追加</strong>到其维护的 <strong>AOF 缓冲区</strong>末尾.</p><p><strong>AOF缓冲区</strong> (aof_buf) 采用 Redis 特有的数据结构 <a href=https://github.com/antirez/sds>SDS (Simple Dynamic String)</a>, 根据命令的类型, 使用不同的方法（<code>catAppendOnlyGenericCommand</code>, <code>catAppendOnlyExpireAtCommand</code>等）, 来对命令进行处理, 最后写入缓冲区.</p><p>如果命令追加时正在进行 AOF <strong>重写</strong>, 这些命令还会追加到<strong>重写缓冲区</strong> <code>aof_rewrite_buffer</code>.</p><h2 id=2-写入文件以及同步-fsync>2 写入文件以及同步 fsync<a hidden class=anchor aria-hidden=true href=#2-写入文件以及同步-fsync>#</a></h2><p>由于硬盘的 I/O 性能较差, 文件读写速度远远比不上 CPU 的处理速度, 那么如果每次文件写入都等待数据写入硬盘, 会整体拉低操作系统的性能. 为了解决这个问题, 操作系统提供了**延迟写（delayed write）**机制来提高硬盘的I/O性能.</p><p>Redis 每次事件轮询结束前（<code>beforeSleep</code>）都会调用函数 <code>flushAppendOnlyFile</code>, 它会把 <strong>AOF 缓冲区</strong>中的数据写入<strong>内核缓冲区</strong>, 并且根据 <strong>appendfsync</strong> 的配置来决定采用何种策略把<strong>内核缓冲区</strong>中的数据写入<strong>磁盘</strong>, 即调用 <code>fsync()</code> , 有三个可选项：</p><ul><li>always：每次都调用<code>fsync()</code>, 安全性最高, 但性能最差</li><li>no：不会调用<code>fsync()</code>. 性能最好, 安全性最差.</li><li>everysec：仅在满足同步条件时调用<code>fsync()</code>. 这是官方推荐的策略, 也是默认配置, 能够兼顾性能和数据安全性, 只有在系统突然宕机的情况下会丢失 1 秒的数据.</li></ul><h2 id=3-重写-rewrite>3 重写 rewrite<a hidden class=anchor aria-hidden=true href=#3-重写-rewrite>#</a></h2><p>随着时间的增加, AOF 文件体积会越来越大, 导致磁盘占用空间更多, 数据恢复时间更长. 为了解决这个问题, Redis 引入了 <strong>AOF 重写 (AOF Rewrite)</strong> 机制, 通过创建新的 AOF 文件, 将旧文件中的多条命令整合成为新文件中的单条命令, 并替换旧文件, 来减少 AOF 文件的体积.</p><h3 id=重写在何时发生><strong>重写在何时发生?</strong><a hidden class=anchor aria-hidden=true href=#重写在何时发生>#</a></h3><p>和 RDB 的触发方式类似, AOF重写可以通过手动或自动触发.</p><ol><li>手动触发：调用<code>bgrewriteaof</code>命令, 如果当前不存在正在执行的 bgsave 或 bgrewriteaof 子进程, 那么重写会立即执行, 否则会等待子进程操作结束后再执行.</li><li>自动触发由两个配置项控制, 只有这两个指标同时满足的时候才会发生重写：<ul><li><code>auto-aof-rewrite-percentage</code>: 当前AOF文件（aof_current_size）和上一次重写发生后AOF文件大小（aof_base_size）相比, 其增加的比例, 默认为100, 即当 aof_current_size == 2 * aof_base_size 时触发</li><li><code>auto-aof-rewrite-min-size</code>: 运行<code>BGREWRITEAOF</code>时AOF文件占用空间最小值, 默认为64MB</li></ul></li></ol><h3 id=重写的流程是怎么样的><strong>重写的流程是怎么样的?</strong><a hidden class=anchor aria-hidden=true href=#重写的流程是怎么样的>#</a></h3><ol><li>bgrewriteaof 触发重写, 判断是否存在 bgsave 或者 bgrewriteaof 正在执行, 如果存在则等待其执行结束再执行</li><li>主进程fork子进程, 防止主进程阻塞无法提供服务</li><li>子进程遍历 Redis 内存快照中数据写入临时 AOF 文件, 同时会将新的写指令写入 aof_buf 和 aof_rewrite_buf 两个重写缓冲区, 前者是为了写回旧的 AOF 文件, 后者是为了后续刷新到临时 AOF 文件中, 防止快照内存遍历时新的写入操作丢失</li><li>子进程结束临时AOF文件写入后, 通知主进程</li><li>主进程会将 aof_rewirte_buf 中的数据写到子进程生成的临时 AOF log 中</li><li>主进程使用临时AOF文件替换旧AOF文件, 完成整个重写过程</li></ol><p>整个过程可以参考下图：</p><p>Redis启动时把<code>aof_base_size</code>初始化为当时aof文件的大小, Redis运行过程中, 当AOF文件重写操作完成时, 会对其进行更新；<code>aof_current_size</code>为<code>serverCron</code>执行时AOF文件的实时大小. 当满足以下两个条件时, AOF文件重写就会触发：</p><h3 id=aof重写会阻塞吗><strong>AOF重写会阻塞吗?</strong><a hidden class=anchor aria-hidden=true href=#aof重写会阻塞吗>#</a></h3><p>AOF 的重写过程是由后台进程 bgrewriteaof 来完成的. 主线程 fork 出后台的 bgrewriteaof 子进程, fork 操作会把主线程的内存拷贝一份给 bgrewriteaof 子进程, 这里面就包含了数据库的最新数据. 然后, bgrewriteaof 子进程逐一把拷贝的数据写成操作, 并记入重写日志, 因此在重写过程中, 只有当 fork 操作发生时会阻塞主线程.</p><h2 id=4-重启并加载-load>4 重启并加载 load<a hidden class=anchor aria-hidden=true href=#4-重启并加载-load>#</a></h2><p>Redis启动后通过<code>loadDataFromDisk</code>函数执行数据加载, 流程大致如下：</p><ol><li>未开启 AOF 的情况下, 只使用 RDB 文件加载数据</li><li>开启 AOF 的情况下, 如果 AOF 文件使用 RDB 头, 那么先使用 RDB, 再使用 AOF , 否则只使用 AOF 加载数据</li></ol><h2 id=总结-1>总结<a hidden class=anchor aria-hidden=true href=#总结-1>#</a></h2><h3 id=aof能保证数据完整性么><strong>AOF能保证数据完整性么?</strong><a hidden class=anchor aria-hidden=true href=#aof能保证数据完整性么>#</a></h3><p>如果在对AOF文件进行写操作时发生了宕机, 或磁盘满了, 由于延迟写的特点, AOF的RESP命令可能会因为被截断而不完整. 发生这种情况时, Redis会按照配置项<code>aof-load-truncated</code> 的值来进行不同的操作：</p><ul><li>yes：尽可能多的加载数据, 并以日志的方式通知用户；</li><li>no：以系统错误的方式产生崩溃, 并禁止重启, 需要用户手动修复文件</li></ul><h3 id=优点-1>优点<a hidden class=anchor aria-hidden=true href=#优点-1>#</a></h3><ul><li>AOF持久化有更好的实时性, 因为使用 every second 作为 fsyn从的默认策略, 极端情况下可能只会丢失一秒的数据</li><li>对 AOF log 的操作只有 append, 不会导致文件损坏；即使最后写入数据被截断, 也很容易使用<code>redis-check-aof</code>工具修复</li><li>重写机制可以保证 AOF log 不占用太大空间, 并且重写过程中新的写操作也会记录到旧的 log 中, 防止数据丢失</li><li>AOF log 具有更高的可读性, 并且可以轻易导出</li></ul><h3 id=缺点-1>缺点<a hidden class=anchor aria-hidden=true href=#缺点-1>#</a></h3><ul><li>对于相同的数据集, AOF 文件通常会比 RDB 文件大</li><li>在写操作较多时, AOF 的延迟会更高</li></ul><h1 id=reference>Reference<a hidden class=anchor aria-hidden=true href=#reference>#</a></h1><p><a href=https://redis.io/docs/management/persistence/>https://redis.io/docs/management/persistence/</a></p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=next href=https://prov1dence.top/posts/disaster-recovery-architecture-on-aws/disaster-recovery-architecture-on-aws-9b3dc135d29c47acbfe19084c57035d5/><span class=title>Next »</span><br><span>Disaster Recovery Architecture on AWS</span></a></nav></footer></article></main><footer class=footer></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>